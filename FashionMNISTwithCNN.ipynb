{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMNISTwithCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9rRTVgKQbuVJ2JqQ/gBq/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6U4Hu-SVPAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qvc4PG2XTSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the Fashion_mnist dataset\n",
        "mnist = keras.datasets.fashion_mnist\n",
        "(train_img, train_lbl), (test_img, test_lbl) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDB_sDpFZrGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_img.shape)\n",
        "train_img = train_img.reshape(60000, 28, 28, 1) # reshaping is required because our CNN is taking an input with 4 dimensions\n",
        "test_img = test_img.reshape(10000, 28, 28, 1) # Initially, the image sets have only 3 dimensions, so add one more by reshaping\n",
        "print(train_img.shape)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwuwtte3cwit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizing our input\n",
        "train_img = train_img/255.0\n",
        "test_img = test_img/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzttyuyWXtjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating our model\n",
        "# this time, we also include Convolution and MaxPooling layers\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Conv2D(64,(3,3),activation='relu',input_shape = (28,28,1)),\n",
        "                          keras.layers.MaxPooling2D(2,2),\n",
        "                          keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "                          keras.layers.MaxPooling2D(2,2),\n",
        "                          keras.layers.Flatten(),\n",
        "                          keras.layers.Dense(128,activation='relu'),\n",
        "                          keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edjfHgP3YwwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling our model\n",
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(train_img, train_lbl, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Kg0OO7ZF4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluating our model on the testing dataset\n",
        "model.evaluate(test_img, test_lbl)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}